# -*- coding: utf-8 -*-
"""
Added code from other source of Social media sentiment analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlug6qpLSDiL33qjXzegYEtkgkdPSMjF
"""

import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('stopwords')

# Preprocess text
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    tokens = word_tokenize(text)
    tokens = [word.lower() for word in tokens]
    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]
    return ' '.join(tokens)

# Load and preprocess dataset
df = pd.read_csv('C:\Users\PC\Downloads\Sentiment model/sentimentdataset1.csv')
df['Sentiment'] = df['Text'].apply(preprocess_text)

# Vectorize text using TF-IDF
tfidf = TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df['Sentiment']).toarray()
y = df['label']

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define and train the model
model = Pipeline([
    ('vect', TfidfVectorizer(max_features=5000)),
    ('clf', MultinomialNB())
])
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print('Accuracy:', accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Save the model
joblib.dump(model, 'sentiment_model.pkl')

# Load the model
def load_model():
    return joblib.load('sentiment_model.pkl')

# Create some test data
unknown = pd.DataFrame({'content': [
    "I love love love love this kitten",
    "I hate hate hate hate this keyboard",
    "I'm not sure how I feel about toast",
    "Did you see the baseball game yesterday?",
    "The package was delivered late and the contents were broken",
    "Trashy television shows are some of my favorites",
    "I'm seeing a Kubrick film tomorrow, I hear not so great things about it.",
    "I find chirping birds irritating, but I know I'm not the only one"
]})

# Vectorize the test data
vectorizer = CountVectorizer()
X_unknown = vectorizer.fit_transform(unknown['content'])

# Display vectorized features
print(vectorizer.get_feature_names_out())

# Display positive, neutral, and negative words (assuming df contains such columns)
print("Positive Words:")
print(df['Positive'].unique())
print("Neutral Words:")
print(df['Neutral'].unique())
print("Negative Words:")
print(df['Negative'].unique())

# Count positive, neutral, and negative words
positive_count = df['Positive'].nunique()
neutral_count = df['Neutral'].nunique()
negative_count = df['Negative'].nunique()

print("\nCount of Positive Words:", positive_count)
print("Count of Neutral Words:", neutral_count)
print("Count of Negative Words:", negative_count)
